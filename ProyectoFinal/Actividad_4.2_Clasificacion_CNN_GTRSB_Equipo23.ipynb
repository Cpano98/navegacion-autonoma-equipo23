{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Proyecto Final\n",
    "## Behavioural Cloning\n",
    "\n",
    "---\n",
    "\n",
    "### Integrantes del Equipo 23:\n",
    "* Carlos Pano Hernández - A01066264 [Campus Estado de México]\n",
    "* Marie Kate Palau - A01705711 [Campus Monterrey]\n",
    "* Edson Ulises Rodríguez Dávalos - A01796057 [Campus CdMx]\n",
    "* Yohanna Ceballos Salomón - A01795115 [Campus Monterrey]\n",
    "\n",
    "---\n",
    "\n",
    "### Escuela de Ingeniería y Ciencias, Tecnológico de Monterrey\n",
    "**Navegación autónoma (MR4010 - Gpo 10)**\n",
    "\n",
    "---\n",
    "\n",
    "#### Profesor Titular:\n",
    "Dr. David Antonio Torres\n",
    "\n",
    "#### Profesor Asistente:\n",
    "Mtra. María Mylen Treviño Elizondo\n",
    "\n",
    "---\n",
    "\n",
    "**Martes 17 de junio del 2025**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import all required libraries\n",
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import Sequential, load_model\n",
    "from tensorflow.keras.layers import Lambda, Conv2D, Flatten, Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.metrics import CosineSimilarity\n",
    "from PIL import Image\n",
    "import os\n",
    "from pathlib import Path\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Detect path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Image dimensions: 320x160\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[4]\u001b[39m\u001b[32m, line 36\u001b[39m\n\u001b[32m     34\u001b[39m \u001b[38;5;66;03m# Load and prepare data\u001b[39;00m\n\u001b[32m     35\u001b[39m train_df = pd.read_csv(\u001b[33m'\u001b[39m\u001b[33mdata/registro_conduccion.csv\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m---> \u001b[39m\u001b[32m36\u001b[39m X = np.array([load_and_preprocess_image(os.path.join(IMG_PATH, fname)) \u001b[38;5;28;01mfor\u001b[39;00m fname \u001b[38;5;129;01min\u001b[39;00m train_df[\u001b[33m'\u001b[39m\u001b[33mnombre_imagen\u001b[39m\u001b[33m'\u001b[39m]])\n\u001b[32m     37\u001b[39m y = train_df[\u001b[33m'\u001b[39m\u001b[33mangulo_direccion\u001b[39m\u001b[33m'\u001b[39m].values\n\u001b[32m     39\u001b[39m \u001b[38;5;66;03m# Split data into train, validation and test sets\u001b[39;00m\n",
      "\u001b[31mKeyboardInterrupt\u001b[39m: "
     ]
    }
   ],
   "source": [
    "# Constants\n",
    "IMG_PATH = 'data/imagenes_capturadas'\n",
    "BATCH_SIZE = 32\n",
    "EPOCHS = 200\n",
    "RANDOM_STATE = 42\n",
    "\n",
    "# Get image dimensions from first image\n",
    "sample_image = Image.open(os.path.join(IMG_PATH, os.listdir(IMG_PATH)[0]))\n",
    "IMG_WIDTH, IMG_HEIGHT = sample_image.size\n",
    "print(f\"Image dimensions: {IMG_WIDTH}x{IMG_HEIGHT}\")\n",
    "\n",
    "# Image preprocessing function\n",
    "def load_and_preprocess_image(file_path):\n",
    "    \"\"\"Load, resize, convert to RGB and normalize image\"\"\"\n",
    "    img = Image.open(file_path).convert('RGB').resize((IMG_WIDTH, IMG_HEIGHT))\n",
    "    return np.array(img) / 255.0\n",
    "\n",
    "# Load and prepare data\n",
    "train_df = pd.read_csv('data/registro_conduccion.csv')\n",
    "X = np.array([load_and_preprocess_image(os.path.join(IMG_PATH, fname)) for fname in train_df['nombre_imagen']])\n",
    "y = train_df['angulo_direccion'].values\n",
    "\n",
    "# Split data into train, validation and test sets\n",
    "X_temp, X_test, y_temp, y_test = train_test_split(X, y, test_size=0.15, random_state=RANDOM_STATE)\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_temp, y_temp, test_size=0.1765, random_state=RANDOM_STATE)\n",
    "\n",
    "# Print dataset sizes\n",
    "print(\"\\nDataset Split:\")\n",
    "print(f\"{'Set':<12} {'Samples':<10} {'Shape':<15}\")\n",
    "print(\"-\" * 40)\n",
    "print(f\"{'Train':<12} {len(X_train):<10} {X_train.shape}\")\n",
    "print(f\"{'Validation':<12} {len(X_val):<10} {X_val.shape}\")\n",
    "print(f\"{'Test':<12} {len(X_test):<10} {X_test.shape}\")\n",
    "\n",
    "# Data augmentation setup\n",
    "train_datagen = ImageDataGenerator(\n",
    "    horizontal_flip=True,\n",
    "    zoom_range=0.2,\n",
    "    width_shift_range=0.1,\n",
    "    height_shift_range=0.1\n",
    ")\n",
    "val_datagen = ImageDataGenerator()\n",
    "\n",
    "# Create data generators\n",
    "train_generator = train_datagen.flow(X_train, y_train, batch_size=BATCH_SIZE)\n",
    "validation_generator = val_datagen.flow(X_val, y_val, batch_size=BATCH_SIZE)\n",
    "\n",
    "# Build CNN model (DAVE-2 inspired architecture)\n",
    "model = Sequential([\n",
    "    Lambda(lambda x: x * 2. - 1., input_shape=(IMG_HEIGHT, IMG_WIDTH, 3)),\n",
    "    Conv2D(24, (5, 5), strides=(2, 2), activation='elu'),\n",
    "    Conv2D(36, (5, 5), strides=(2, 2), activation='relu'),\n",
    "    Conv2D(48, (5, 5), strides=(2, 2), activation='relu'),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Conv2D(64, (3, 3), activation='relu'),\n",
    "    Flatten(),\n",
    "    Dense(1164, activation='relu'),\n",
    "    Dense(100, activation='relu'),\n",
    "    Dense(50, activation='relu'),\n",
    "    Dense(10, activation='relu'),\n",
    "    Dense(1, activation='tanh')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    loss='mse',\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    metrics=[CosineSimilarity()]\n",
    ")\n",
    "\n",
    "# Train model\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=validation_generator\n",
    ")\n",
    "\n",
    "# Evaluate model\n",
    "test_loss, test_acc = model.evaluate(X_test, y_test, verbose=1)\n",
    "print(\"\\nModel Evaluation:\")\n",
    "print(f\"{'Metric':<20} {'Value':<10}\")\n",
    "print(\"-\" * 30)\n",
    "print(f\"{'Test Accuracy':<20} {test_acc:.4f}\")\n",
    "print(f\"{'Test Loss':<20} {test_loss:.4f}\")\n",
    "\n",
    "# Plot training history\n",
    "plt.figure(figsize=(12, 5))\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['cosine_similarity'], label='Train')\n",
    "plt.plot(history.history['val_cosine_similarity'], label='Validation')\n",
    "plt.title('Cosine Similarity')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Similarity')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train')\n",
    "plt.plot(history.history['val_loss'], label='Validation')\n",
    "plt.title('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Model predictions and analysis\n",
    "y_pred = model.predict(X_test)\n",
    "errors = y_pred.flatten() - y_test\n",
    "abs_errors = np.abs(errors)\n",
    "\n",
    "# Plot predictions analysis\n",
    "plt.figure(figsize=(15, 12))\n",
    "plt.subplot(2, 2, 1)\n",
    "plt.scatter(y_test, y_pred, alpha=0.5)\n",
    "plt.plot([-1,1], [-1,1], 'r--')\n",
    "plt.xlabel('True Values')\n",
    "plt.ylabel('Predictions')\n",
    "plt.title('Predictions vs True Values')\n",
    "plt.grid(True)\n",
    "\n",
    "plt.subplot(2, 2, 2)\n",
    "plt.hist(errors, bins=30, alpha=0.7, color='green')\n",
    "plt.xlabel('Error')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Error Distribution')\n",
    "\n",
    "plt.subplot(2, 2, 3)\n",
    "plt.plot(abs_errors, color='orange')\n",
    "plt.xlabel('Sample Index')\n",
    "plt.ylabel('Absolute Error')\n",
    "plt.title('Absolute Error by Sample')\n",
    "\n",
    "plt.subplot(2, 2, 4)\n",
    "error_bins = [-np.inf, 0.1, 0.3, np.inf]\n",
    "error_labels = ['Small', 'Medium', 'Large']\n",
    "error_categories = np.digitize(abs_errors, bins=error_bins)\n",
    "cm = confusion_matrix(error_categories, error_categories, labels=[1, 2, 3])\n",
    "sns.heatmap(cm, annot=True, fmt='d', xticklabels=error_labels, yticklabels=error_labels, cmap='YlOrRd')\n",
    "plt.xlabel('Predicted Error')\n",
    "plt.ylabel('True Error')\n",
    "plt.title('Error Confusion Matrix')\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# Save model\n",
    "model.save('modelo_conduccion.h5')\n",
    "print(\"\\nModel saved as 'modelo_conduccion.h5'\")\n",
    "\n",
    "# Prediction function\n",
    "def cargar_y_predecir(ruta_imagen):\n",
    "    \"\"\"Load model and predict steering angle for an image\"\"\"\n",
    "    modelo_cargado = load_model('modelo_conduccion.h5', \n",
    "                              custom_objects={'mse': tf.keras.losses.MeanSquaredError()})\n",
    "    img = load_and_preprocess_image(ruta_imagen)\n",
    "    return modelo_cargado.predict(np.expand_dims(img, axis=0))[0][0]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "MASTER-AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
