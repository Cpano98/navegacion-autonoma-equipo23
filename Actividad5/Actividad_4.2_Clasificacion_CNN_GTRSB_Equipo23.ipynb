{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Actividad 4.2\n",
    "## Ejercicio de Detección de Señales de Tránsito\n",
    "\n",
    "---\n",
    "\n",
    "### Integrantes del Equipo 23:\n",
    "* Carlos Pano Hernández - A01066264 [Campus Estado de México]\n",
    "* Marie Kate Palau - A01705711 [Campus Monterrey]\n",
    "* Edson Ulises Rodríguez Dávalos - A01796057 [Campus CdMx]\n",
    "* Yohanna Ceballos Salomón - A01795115 [Campus Monterrey]\n",
    "\n",
    "---\n",
    "\n",
    "### Escuela de Ingeniería y Ciencias, Tecnológico de Monterrey\n",
    "**Navegación autónoma (MR4010 - Gpo 10)**\n",
    "\n",
    "---\n",
    "\n",
    "#### Profesor Titular:\n",
    "Dr. David Antonio Torres\n",
    "\n",
    "#### Profesor Asistente:\n",
    "Mtra. María Mylen Treviño Elizondo\n",
    "\n",
    "---\n",
    "\n",
    "**Sábado 07 de junio del 2025**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Library Imports and Setup\n",
    "This section contains all the necessary library imports for data manipulation, image processing, deep learning, and visualization that we'll use throughout this notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OS and file handling\n",
    "import os\n",
    "import glob\n",
    "from PIL import Image\n",
    "\n",
    "# Data manipulation and numerical computations\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "# Image processing\n",
    "import cv2\n",
    "from skimage.feature import hog\n",
    "\n",
    "# Data visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.image as mpimg\n",
    "import seaborn as sns\n",
    "\n",
    "# Deep learning with TensorFlow/Keras\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from skimage.feature import hog\n",
    "from tensorflow.keras.utils import plot_model\n",
    "\n",
    "# Additional Keras imports\n",
    "import keras\n",
    "from keras.optimizers import Adam\n",
    "\n",
    "# Configure matplotlib for Jupyter\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2. Data Loading and Preprocessing\n",
    "This section handles loading the training and test data from CSV files, extracting key image dimensions, and setting up important constants that will be used throughout the model training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the CSV files\n",
    "train_df = pd.read_csv('data/Train.csv')\n",
    "test_df = pd.read_csv('data/Test.csv')\n",
    "\n",
    "print(train_df.head())\n",
    "print('*'*100)\n",
    "print(test_df.head())\n",
    "\n",
    "# Get image dimensions from training data\n",
    "IMG_WIDTH = train_df['Width'].median()\n",
    "IMG_HEIGHT = train_df['Height'].median()\n",
    "NUM_CHANNELS = 3  # RGB images\n",
    "NUM_CLASSES = len(train_df['ClassId'].unique())\n",
    "\n",
    "print(f\"Image dimensions: {IMG_WIDTH}x{IMG_HEIGHT}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Loading and Preprocessing Images\n",
    "The following code block loads and preprocesses the traffic sign images from the file paths specified in our training and test datasets. Each image is:\n",
    "- Loaded from disk.\n",
    "- Resized to consistent dimensions ({IMG_WIDTH}x{IMG_HEIGHT}).\n",
    "- Normalized to [0,1] range.\n",
    "- Converted to numpy arrays for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to load and preprocess images\n",
    "def load_and_preprocess_image(file_path):\n",
    "    # Load image\n",
    "    img = Image.open(file_path)\n",
    "    # Resize to median dimensions\n",
    "    img = img.resize((int(IMG_WIDTH), int(IMG_HEIGHT)))\n",
    "    # Convert to numpy array and normalize\n",
    "    img_array = np.array(img) / 255.0\n",
    "    return img_array\n",
    "\n",
    "# Prepare training data -> For this exercise we are using the data from the Train.csv file under Data folder\n",
    "X_train = np.array([load_and_preprocess_image(os.path.join('data', path)) for path in train_df['Path']])\n",
    "y_train = train_df['ClassId'].values\n",
    "\n",
    "# Prepare test data -> For this exercise we are using the data from the Test.csv file under Data folder\n",
    "X_test = np.array([load_and_preprocess_image(os.path.join('data', path)) for path in test_df['Path']])\n",
    "y_test = test_df['ClassId'].values\n",
    "\n",
    "print(f\"Training data shape: {X_train.shape}\")\n",
    "print(f\"Test data shape: {X_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Loading and Preprocessing Images\n",
    "The following code block loads and preprocesses the traffic sign images from the file paths specified in our training and test datasets. Each image is:\n",
    "- Loaded from disk.\n",
    "- Resized to consistent dimensions ({IMG_WIDTH}x{IMG_HEIGHT}).\n",
    "- Normalized to [0,1] range.\n",
    "- Converted to numpy arrays for model training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_muestras = []\n",
    "n_digitos = 10\n",
    "\n",
    "for n in range(n_digitos):\n",
    "    x_sel = X_train[y_train == n]\n",
    "    n_muestras.append(len(x_sel))\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.bar(range(0,n_digitos), n_muestras)\n",
    "plt.xlabel(\"Dígito\")\n",
    "plt.ylabel(\"Número de Muestras\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Model Architecture\n",
    "\n",
    "The following code block defines and compiles our CNN model architecture for traffic sign classification. The model consists of:\n",
    "- Three convolutional blocks with increasing filter sizes (32->64->128).\n",
    "- Each block has batch normalization, max pooling and dropout for regularization.\n",
    "- Dense layers for final classification across 43 traffic sign categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create CNN model\n",
    "model = Sequential([\n",
    "    # First Convolutional Block\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same', \n",
    "                       input_shape=(int(IMG_HEIGHT), int(IMG_WIDTH), NUM_CHANNELS)),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(32, (3, 3), activation='relu', padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    \n",
    "    # Second Convolutional Block\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(64, (3, 3), activation='relu', padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    \n",
    "    # Third Convolutional Block\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Conv2D(128, (3, 3), activation='relu', padding='same'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.MaxPooling2D(2, 2),\n",
    "    keras.layers.Dropout(0.25),\n",
    "    \n",
    "    # Flatten and Dense Layers\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(512, activation='relu'),\n",
    "    keras.layers.BatchNormalization(),\n",
    "    keras.layers.Dropout(0.5),\n",
    "    keras.layers.Dense(NUM_CLASSES, activation='softmax')\n",
    "])\n",
    "\n",
    "# Compile model\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=0.001),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "# Display model summary\n",
    "print(model.summary())\n",
    "\n",
    "# Generate and save model architecture diagram\n",
    "plot_model(model, to_file='model_architecture.png', show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Display the architecture diagram\n",
    "plt.figure(figsize=(10,10))\n",
    "img = plt.imread('model_architecture.png')\n",
    "plt.imshow(img)\n",
    "plt.axis('off') # Hide axes\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Model Training and Evaluation\n",
    "In this section, we train the CNN model on our traffic sign dataset and evaluate its performance. We use categorical crossentropy loss, the Adam optimizer, and track both accuracy and loss metrics during training."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = model.fit(\n",
    "    X_train, \n",
    "    tf.keras.utils.to_categorical(y_train, NUM_CLASSES),\n",
    "    validation_split=0.5,\n",
    "    epochs=10,\n",
    "    batch_size=400,\n",
    "    verbose=1,\n",
    "    shuffle=True\n",
    ")\n",
    "\n",
    "scores = model.evaluate(X_test, tf.keras.utils.to_categorical(y_test, NUM_CLASSES), verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. Visualizing Training Results\n",
    "The following section creates plots to visualize the model's training progress, showing both the loss and accuracy metrics over epochs for training and validation data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create figure with 2 subplots\n",
    "plt.figure(figsize=(12,5))\n",
    "\n",
    "# Plot training & validation loss\n",
    "plt.subplot(1,2,1)\n",
    "plt.plot(history.history['loss'], label='Training Loss')\n",
    "plt.plot(history.history['val_loss'], label='Validation Loss')\n",
    "plt.title('Model Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "# Plot training & validation accuracy \n",
    "plt.subplot(1,2,2)\n",
    "plt.plot(history.history['accuracy'], label='Training Accuracy')\n",
    "plt.plot(history.history['val_accuracy'], label='Validation Accuracy')\n",
    "plt.title('Model Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Testing with Multiple Sample Images\n",
    "The following section demonstrates how to use the trained model to classify multiple traffic sign images. We load, preprocess, and predict on test images from the Meta folder to verify the model's performance on real-world data. The images are displayed in a grid format with their predicted sign types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_image_path = 'data/Meta/'\n",
    "test_images = glob.glob(os.path.join(test_image_path, '*.png'))\n",
    "\n",
    "# Create multiple figures if more than 16 images\n",
    "num_images = len(test_images)\n",
    "num_figures = (num_images - 1) // 16 + 1\n",
    "\n",
    "for fig_num in range(num_figures):\n",
    "    plt.figure(figsize=(15, 15))\n",
    "    start_idx = fig_num * 16\n",
    "    end_idx = min(start_idx + 16, num_images)\n",
    "    \n",
    "    for idx, image_path in enumerate(test_images[start_idx:end_idx]):\n",
    "        # Load and preprocess image\n",
    "        img = Image.open(image_path)\n",
    "        img_arr = np.asarray(img)\n",
    "        img_rs = cv2.resize(img_arr, (43, 43))\n",
    "        img_gray = cv2.cvtColor(img_rs, cv2.COLOR_BGR2GRAY)\n",
    "        img_not = cv2.bitwise_not(img_gray)\n",
    "        \n",
    "        # Display image\n",
    "        plt.subplot(4, 4, idx+1)\n",
    "        plt.imshow(img_not, cmap=plt.get_cmap('gray'))\n",
    "        plt.axis('off')\n",
    "        \n",
    "        # Prepare for prediction\n",
    "        img_not = img_not/255\n",
    "        img_resh = img_not.reshape(1, 43, 43, 1)\n",
    "        img_resh = np.repeat(img_resh, 3, axis=-1)\n",
    "        \n",
    "        # Make prediction\n",
    "        prediction = np.argmax(model.predict(img_resh, verbose=0), axis=-1)\n",
    "        plt.title(f'Sign Type: {prediction[0]}')\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "master-ai-tec",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
